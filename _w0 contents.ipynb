{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w1 - summarize content  \n",
    "- summaries text with **openAI** or open source **Ollama** APIs\n",
    "- create a brochure from scraped web pages\n",
    "- create a technical tutor\n",
    "\n",
    "## w2 - Function calls. Create webapp chatbot with multi-modal AI\n",
    "Create webapp and chatbot for airline costumer service that finds the price of a ticket to a city, generates image of the city with the main tourist attractions and speaks the answer back.\n",
    "\n",
    "- day1: Anthropic and google APIs and chat between two AIs\n",
    "- day2: Web interface with Gradio\n",
    "- day3: Cerate chat with gradio \n",
    "- day4: add function calls (tools) to an AI chatbot. Add tool to find the ticket price\n",
    "- day5: Add Agents to AI - multi-modal AI\n",
    "\n",
    "## w3 - open source Gen AI with Hugging Face (HF)\n",
    "HF libraries \n",
    " - transformers: provides APIs and tools to easily download and train state-of-the-art pretrained models.\n",
    " - datasets: provides access to HF datasets \n",
    " - tokenizers - provides an implementation of todayâ€™s most used tokenizers, with a focus on performance and versatility\n",
    " - perf (Parameter-Efficient Fine-Tuning): for fine-tuning pre-trained models \n",
    " - trl (Transformer Reinforcement Learning): for training and fine-tuning transformer models\n",
    "\n",
    "### Days\n",
    " - day2: Pipelines - part of the transformers library designed to simplify the use of pre-trained models\n",
    " - day3: Tokenizers - library to tokenize the text\n",
    " - day4: Use different HF models\n",
    " - day5: Create minutes of meetings. \n",
    " - Synthetic data generator\n",
    "\n",
    " ## w4 - Evaluating models and deploying on Hugging Face\n",
    " - day1-2: useful links:\n",
    "    - [hugging Face open models leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/)\n",
    "    - [Embedding Models Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "    - [HF LLM-Perf Leaderboard ](https://huggingface.co/spaces/optimum/llm-perf-leaderboard)\n",
    "    - [HF coding models leaderboard](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard)\n",
    "    - [HF explore financial analysis spaces](https://huggingface.co/spaces?category=financial-analysis)\n",
    "    - [human ranking](https://lmarena.ai/)\n",
    "    - [vellum leaderboard - includes API cost](https://www.vellum.ai/llm-leaderboard)\n",
    "    - [artificialanalysis leaderboard](https://artificialanalysis.ai/models)\n",
    "    - [task specific models leaderboard](https://scale.com/leaderboard)\n",
    " - day3: Convert python to c++ code and deploy in a gradio app\n",
    " - day4: Deploying models on Hugging Face\n",
    " ## w5 Implementing a RAG pipeline\n",
    " - day1: Brute force RAG - Understand the idea od RAG\n",
    " - day2: load text docs and split in chunks with LangChain\n",
    " - day3: Vectorize some docs - LangChain for vector embeddings \n",
    " - day4: Implement a RAG pipeline. \n",
    " - day5: Optimizing RAG systems \n",
    " ## w6 Fine Tune LLM with Lora/qLora - frontier model  \n",
    " - day1: Get the data from HF check it out and curate it. \n",
    "   - remove text that does not add value - like batteries included \n",
    "   - replace weird chars, and excess white spaces and item parts numbers\n",
    "   - create a prompt\n",
    " - day2: Create clean dataset and model deployment pipeline. \n",
    "   - day2.1: Load multiple data sets in parallel to save time\n",
    "   - day2.2: balance the dataset so that it contains similar sample sizes for different prices and categories. \n",
    "   - day2.3: create train and test datasets.\n",
    "   - day2.4: LLM Deployment pipeline\n",
    "      1. understand the business problem \n",
    "         - What data is available.\n",
    "         - no fictional requirements - cost constrains, scalability latency \n",
    "         - time to market - implementation timeline\n",
    "         - how to measure - business focused metrics \n",
    "      2. preparation - test baseline models, prep dataset \n",
    "         - research existing solutions \n",
    "         - compare LLMs - context length, price, license, leader board, specialist scores. \n",
    "         - curate the data - clean, preprocess, balance, split. \n",
    "      3. select model/s \n",
    "         - choose LLMs\n",
    "         - experiment with them \n",
    "         train and validate with curated data\n",
    "      4. Optimize the model\n",
    "         - prompting\n",
    "         - RAG\n",
    "         - fine-tunning \n",
    "      5. productionalize the model \n",
    "         - define an API \n",
    "         - identify hosting and deployment architecture \n",
    "         - address scaling, monitoring and security\n",
    "         - measure the business focussed metrics \n",
    "         - continues measure and model improvement - retrain model. \n",
    " - day3: Create a baseline models for comparison\n",
    "   - use average price as predictor \n",
    "   - use linear regression with feature engineering (product weight, sellers rank, top brans...)\n",
    "   - use linear regression with bag of words for features \n",
    "   - use linear regression with word vectoriser for features.\n",
    "   - use SVM with word vectoriser for features.\n",
    "   - use Random forest with word vectoriser for features.\n",
    " - day4: Use frontier LLM  for prediction without training \n",
    "   - check out how a human price predictor will do. \n",
    "   - test the frontier models without training it. GPT-4o beats all other base models even without training. \n",
    " - day5: fine-tune frontier model. \n",
    "   - prepare training data in jsonl format as required by the models. The model have to receive, system, user and assistant prompts where:\n",
    "      - system prompt - is what we ask the model to do.\n",
    "      - user prompt - is the text or the data the model will use for the prediction but without the actual prediction.\n",
    "      - assistant prompt - is the actual prediction - what the model should return. \n",
    "   - run the training \n",
    "   - evaluate the results and tweak if needed \n",
    "## w7 Fine Tune LLM with Lora/qLora - open source model\n",
    "   - day1: into to qlora (quantization low rank adaptation). \n",
    "      - lora is e technic to where a two lower rank matrices are applied to one or some of the layers of the original model. In effect instead of training all the original weight of the target layer we train the tow lower rank matrices that have few weights.\n",
    "      - Quantization is a technic to reduce the precision of the numbers in the way they are stored in bits.\n",
    "      - lora hyper parameters: \n",
    "         - R (Rank): how many dimensions will be used for the lower rank matrices. Start with 8 and increase to 16, 32... to see if the results are better \n",
    "         - alfa: a scaling factor used to multiply the matrices. The bigger alfa the more effect from the matrices. Typical alfa is 2*R \n",
    "         - target modules: which layers of the neural network are adapted. Typically starting with the attention layers. \n",
    "         - dropout - percentage of the weights to drop out for controlling the bias. Usually between 0.05 and 0.2.\n",
    "   - day2: Model evaluation\n",
    "      - model size (number of parameters) - depends on what machine we have\n",
    "      - base vs instruct model. if it is one purpose model base model may be a better start. If we want to take advantage of the system, user, assistant structure instruct model may be better.\n",
    "      - what model to use llama vs Qwen, Gemam,Phi... Selecting a higher score instruct model may mean that the base model is more susceptible to training \n",
    "   - day3-4: training \n",
    "   - day5 test the fine tuned model \n",
    "## w8 Build autonomous multi-Agent system\n",
    "- day1: Use Modal cloud to deploy services. Modal is a space to run code remotely:\n",
    "   - Set up connection to Modal \n",
    "   - run local app on Modal. \n",
    "   - deploy app on Modal. This allows for apps to be run on the Modal cloud via python or REST API web point.\n",
    "   - Introducing the agents class - see `w8 Agents/agents. This folder collects all agents in classes and makes them easy to use. \n",
    "-  day2: Build two more agents to predict the price. One will use use RAG and the other will use Random forest.\n",
    "   1. create a RAG database with our 400,000 training data\n",
    "   2. visualize in 2D\n",
    "   3. visualize in 3D\n",
    "   4. build and test a RAG pipeline with GPT-4o-mini\n",
    "   5. Create a Ensemble pricer that allows contributions from all the pricers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
